{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O49XQD8rwNUF"
      },
      "source": [
        "![Grounded SAM Inpainting Demo](https://github.com/IDEA-Research/Grounded-Segment-Anything/raw/main/assets/grounded_sam_inpainting_demo.png)\n",
        "\n",
        "## Why this project?\n",
        "\n",
        "- [Segment Anything](https://github.com/facebookresearch/segment-anything) is a strong segmentation model. But it need prompts (like boxes/points) to generate masks.\n",
        "- [Grounding DINO](https://github.com/IDEA-Research/GroundingDINO) is a strong zero-shot detector which enable to generate high quality boxes and labels with free-form text.\n",
        "- The combination of the two models enable **to detect and segment everything** with text inputs!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vd8QKJuhlWg"
      },
      "source": [
        "if NameError: name '_C' is not defined\n",
        "reference this solution: https://github.com/IDEA-Research/GroundingDINO/issues/8#issuecomment-1541892708\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAi4IkEfKi5K"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSJqZHr3JTSB",
        "outputId": "29346d75-09a0-4c1f-b383-c1ea56c1321d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'Grounded-Segment-Anything' already exists and is not an empty directory.\n",
            "/content/Grounded-Segment-Anything\n",
            "/content/Grounded-Segment-Anything/GroundingDINO\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for groundingdino (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "/content/Grounded-Segment-Anything/segment_anything\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content/Grounded-Segment-Anything\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/IDEA-Research/Grounded-Segment-Anything\n",
        "\n",
        "%cd /content/Grounded-Segment-Anything\n",
        "!pip install -q -r requirements.txt\n",
        "%cd /content/Grounded-Segment-Anything/GroundingDINO\n",
        "!pip install -q .\n",
        "%cd /content/Grounded-Segment-Anything/segment_anything\n",
        "!pip install -q .\n",
        "%cd /content/Grounded-Segment-Anything"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRkQUrtjKpbh"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Osu6KERJeTN",
        "outputId": "feb48b68-1ee0-46c5-aa60-755d0c2fb940"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/Grounded-Segment-Anything/GroundingDINO/groundingdino/models/GroundingDINO/ms_deform_attn.py:31: UserWarning: Failed to load custom C++ ops. Running on CPU mode Only!\n",
            "  warnings.warn(\"Failed to load custom C++ ops. Running on CPU mode Only!\")\n",
            "/usr/local/lib/python3.10/dist-packages/groundingdino/models/GroundingDINO/ms_deform_attn.py:31: UserWarning: Failed to load custom C++ ops. Running on CPU mode Only!\n",
            "  warnings.warn(\"Failed to load custom C++ ops. Running on CPU mode Only!\")\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "sys.path.append(os.path.join(os.getcwd(), \"GroundingDINO\"))\n",
        "\n",
        "import argparse\n",
        "import copy\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from torchvision.ops import box_convert\n",
        "\n",
        "# Grounding DINO\n",
        "import GroundingDINO.groundingdino.datasets.transforms as T\n",
        "from GroundingDINO.groundingdino.models import build_model\n",
        "from GroundingDINO.groundingdino.util import box_ops\n",
        "from GroundingDINO.groundingdino.util.slconfig import SLConfig\n",
        "from GroundingDINO.groundingdino.util.utils import clean_state_dict, get_phrases_from_posmap\n",
        "from GroundingDINO.groundingdino.util.inference import annotate, load_image, predict\n",
        "\n",
        "import supervision as sv\n",
        "\n",
        "# segment anything\n",
        "from segment_anything import build_sam, SamPredictor\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# diffusers\n",
        "import PIL\n",
        "import requests\n",
        "import torch\n",
        "from io import BytesIO\n",
        "from diffusers import StableDiffusionInpaintPipeline\n",
        "\n",
        "\n",
        "from huggingface_hub import hf_hub_download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFnZ_nwcKuUk"
      },
      "source": [
        "## Load models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "004CGse3NRS2"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzhOnA6ALQlo"
      },
      "source": [
        "### Grounding DINO model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPTgK04-J1U4"
      },
      "outputs": [],
      "source": [
        "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
        "    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
        "\n",
        "    args = SLConfig.fromfile(cache_config_file)\n",
        "    args.device = device\n",
        "    model = build_model(args)\n",
        "\n",
        "    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
        "    checkpoint = torch.load(cache_file, map_location=device)\n",
        "    log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
        "    print(\"Model loaded from {} \\n => {}\".format(cache_file, log))\n",
        "    _ = model.eval()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73fWWbE0KBZZ",
        "outputId": "9546c60a-b283-45db-bdfe-0fff8d0a5356"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final text_encoder_type: bert-base-uncased\n",
            "Model loaded from /root/.cache/huggingface/hub/models--ShilongLiu--GroundingDINO/snapshots/a94c9b567a2a374598f05c584e96798a170c56fb/groundingdino_swinb_cogcoor.pth \n",
            " => _IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n"
          ]
        }
      ],
      "source": [
        "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
        "ckpt_filenmae = \"groundingdino_swinb_cogcoor.pth\"\n",
        "ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\"\n",
        "\n",
        "\n",
        "groundingdino_model = load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename, device)\n",
        "\n",
        "groundingdino_model = groundingdino_model.to('cuda:0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRsDao4wLV4t"
      },
      "source": [
        "### SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNyrl-WMLVQs",
        "outputId": "2660c26c-5c32-452a-8503-186058bf7d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-31 19:27:15--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.225.47.41, 13.225.47.21, 13.225.47.11, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.225.47.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
            "Saving to: ‘sam_vit_h_4b8939.pth.1’\n",
            "\n",
            "sam_vit_h_4b8939.pt 100%[===================>]   2.39G  94.0MB/s    in 28s     \n",
            "\n",
            "2024-01-31 19:27:43 (87.5 MB/s) - ‘sam_vit_h_4b8939.pth.1’ saved [2564550879/2564550879]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "\n",
        "sam_checkpoint = 'sam_vit_h_4b8939.pth'\n",
        "\n",
        "sam_predictor = SamPredictor(build_sam(checkpoint=sam_checkpoint).to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiDBwfq0LeVh"
      },
      "source": [
        "### Stable Diffusion (Inpainting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161,
          "referenced_widgets": [
            "9b57f9de198c42988690102e2f966db6",
            "c52bd40f5ec24419a2c4ec0914bf7d15",
            "782d5564247c4f1f98129c542d8683f8",
            "e4d6a1bdac2e45ef85e497074ac3f7d5",
            "4a579c847c254c9fb9bd647ea8e46246",
            "4b8bcb3e61b844d182f7310ded587cfc",
            "fbf698b3b1284c8d9e596ea37132c6aa",
            "8fbefef14f994a039025154df0dcb7dc",
            "57cb22a8a8b14c77a280fa01e853106b",
            "427784430f794a82ad4e6fbc9bb00a94",
            "6539f3fea91d4c93b61a53137fd3ac85"
          ]
        },
        "id": "KmSGdNxYLkGk",
        "outputId": "42879ffc-3229-4c5a-b93b-b7e43c2cb009"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b57f9de198c42988690102e2f966db6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sd_pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
        "    torch_dtype=torch.float16,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y86GkczAOAVx"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dad-C9F_OWn7",
        "outputId": "cd10e3ff-1916-4c1a-9079-7b1cfe2b1a4e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'requests' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41216\\3965476292.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mlocal_image_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"assets/apple.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mimage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mdownload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mimage_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41216\\3965476292.py\u001b[0m in \u001b[0;36mdownload_image\u001b[1;34m(url, image_file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdownload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Status code error: {}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
          ]
        }
      ],
      "source": [
        "# Load image\n",
        "def download_image(url, image_file_path):\n",
        "    r = requests.get(url, timeout=4.0)\n",
        "    if r.status_code != requests.codes.ok:\n",
        "        assert False, 'Status code error: {}.'.format(r.status_code)\n",
        "\n",
        "    with Image.open(BytesIO(r.content)) as im:\n",
        "        im.save(image_file_path)\n",
        "    print('Image downloaded from url: {} and saved to: {}.'.format(url, image_file_path))\n",
        "\n",
        "\n",
        "# local_image_path = \"assets/apple.png\"\n",
        "# image_url = \"https://huggingface.co/datasets/twoyoung/apple/resolve/main/apple2.png\"\n",
        "\n",
        "local_image_path = \"assets/apple.jpg\"\n",
        "image_url = \"\"\n",
        "download_image(image_url, local_image_path)\n",
        "image_source, image = load_image(local_image_path)\n",
        "Image.fromarray(image_source)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaEIyVwjOCam"
      },
      "source": [
        "## Grounding DINO for detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm8fGM5XOkqN"
      },
      "outputs": [],
      "source": [
        "# detect object using grounding DINO\n",
        "def detect(image, text_prompt, model, box_threshold = 0.3, text_threshold = 0.25):\n",
        "  boxes, logits, phrases = predict(\n",
        "      model=model,\n",
        "      image=image,\n",
        "      caption=text_prompt,\n",
        "      box_threshold=box_threshold,\n",
        "      text_threshold=text_threshold\n",
        "  )\n",
        "\n",
        "  annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
        "  annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
        "  return annotated_frame, boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "YVjdmTWOPxTy",
        "outputId": "fc959f4d-48f1-4b05-b0e6-9a5918dbc4f7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'detect' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41216\\3873850936.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mannotated_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetected_boxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_prompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fruits\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroundingdino_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotated_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'detect' is not defined"
          ]
        }
      ],
      "source": [
        "annotated_frame, detected_boxes = detect(image, text_prompt=\"fruits\", model=groundingdino_model)\n",
        "Image.fromarray(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p7cHFDKQw5W"
      },
      "source": [
        "## SAM for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8-1lhHjQ2dm"
      },
      "outputs": [],
      "source": [
        "def segment(image, sam_model, boxes):\n",
        "  sam_model.set_image(image)\n",
        "  H, W, _ = image.shape\n",
        "  boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.Tensor([W, H, W, H])\n",
        "\n",
        "  transformed_boxes = sam_model.transform.apply_boxes_torch(boxes_xyxy.to(device), image.shape[:2])\n",
        "  masks, _, _ = sam_model.predict_torch(\n",
        "      point_coords = None,\n",
        "      point_labels = None,\n",
        "      boxes = transformed_boxes,\n",
        "      multimask_output = False,\n",
        "      )\n",
        "  return masks.cpu()\n",
        "\n",
        "\n",
        "def draw_mask(mask, image, random_color=True):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.8])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "\n",
        "    annotated_frame_pil = Image.fromarray(image).convert(\"RGBA\")\n",
        "    mask_image_pil = Image.fromarray((mask_image.cpu().numpy() * 255).astype(np.uint8)).convert(\"RGBA\")\n",
        "\n",
        "    return np.array(Image.alpha_composite(annotated_frame_pil, mask_image_pil))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "Rre8LHzPvgEI",
        "outputId": "bc01dd73-af94-4dfd-b0cc-515273d39d0d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'segment' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41216\\2665415383.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msegmented_frame_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msam_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetected_boxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mannotated_frame_with_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegmented_frame_masks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotated_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotated_frame_with_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'segment' is not defined"
          ]
        }
      ],
      "source": [
        "segmented_frame_masks = segment(image_source, sam_predictor, boxes=detected_boxes)\n",
        "annotated_frame_with_mask = draw_mask(segmented_frame_masks[12][0], annotated_frame)\n",
        "Image.fromarray(annotated_frame_with_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OIgzr21rz9l"
      },
      "outputs": [],
      "source": [
        "def segment(image, sam_model, boxes):\n",
        "  sam_model.set_image(image)\n",
        "  H, W, _ = image.shape\n",
        "  boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.Tensor([W, H, W, H])\n",
        "\n",
        "  transformed_boxes = sam_model.transform.apply_boxes_torch(boxes_xyxy.to(device), image.shape[:2])\n",
        "  masks, _, _ = sam_model.predict_torch(\n",
        "      point_coords = None,\n",
        "      point_labels = None,\n",
        "      boxes = transformed_boxes,\n",
        "      multimask_output = False,\n",
        "      )\n",
        "  return masks.cpu()\n",
        "\n",
        "\n",
        "def draw_masks(masks, image, random_color=True):\n",
        "  annotated_frame_pil = Image.fromarray(image).convert(\"RGBA\")\n",
        "\n",
        "  for mask in masks:\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.8])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    mask_image_pil = Image.fromarray((mask_image.cpu().numpy() * 255).astype(np.uint8)).convert(\"RGBA\")\n",
        "    annotated_frame_pil = Image.alpha_composite(annotated_frame_pil, mask_image_pil)\n",
        "\n",
        "  return np.array(annotated_frame_pil)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "puUUEAAjSlug",
        "outputId": "b0d7667b-b5e4-43bb-95f0-62a3a70f4152"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'segment' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41216\\4021379253.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msegmented_frame_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msam_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetected_boxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mannotated_frame_with_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegmented_frame_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotated_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotated_frame_with_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'segment' is not defined"
          ]
        }
      ],
      "source": [
        "segmented_frame_masks = segment(image_source, sam_predictor, boxes=detected_boxes)\n",
        "annotated_frame_with_masks = draw_masks(segmented_frame_masks, annotated_frame)\n",
        "Image.fromarray(annotated_frame_with_masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct786WclTVdN"
      },
      "source": [
        "## Stable Diffusion for inpainting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rSWPBj2Z8Mb_",
        "outputId": "3b8a5d86-e20b-4117-e13b-8759aaea57f8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Image' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41216\\619685871.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage_source_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbackground_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegmented_frame_masks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmasks_image_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackground_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RGBA\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        }
      ],
      "source": [
        "image_source_pil = Image.fromarray(image_source)\n",
        "\n",
        "background_image = np.ones_like(segmented_frame_masks[0][0].cpu().numpy(), dtype=np.uint8)*255\n",
        "masks_image_pil = Image.fromarray(background_image).convert(\"RGBA\")\n",
        "\n",
        "for i in range(len(segmented_frame_masks)):\n",
        "    mask = segmented_frame_masks[i][0].cpu().numpy()\n",
        "\n",
        "    # Create an RGBA image with a transparent background\n",
        "    alpha_channel = (mask != 0).astype(np.uint8) * 255\n",
        "    image_mask_pil = Image.fromarray(np.dstack([mask, mask, mask, alpha_channel]), \"RGBA\")\n",
        "\n",
        "    # Blend the mask onto the image without accumulating the black background\n",
        "    masks_image_pil = Image.alpha_composite(masks_image_pil, image_mask_pil)\n",
        "\n",
        "# Display the resulting image containing all masks with transparent backgrounds\n",
        "display(*[image_source_pil, masks_image_pil])\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "427784430f794a82ad4e6fbc9bb00a94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a579c847c254c9fb9bd647ea8e46246": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8bcb3e61b844d182f7310ded587cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57cb22a8a8b14c77a280fa01e853106b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6539f3fea91d4c93b61a53137fd3ac85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "782d5564247c4f1f98129c542d8683f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fbefef14f994a039025154df0dcb7dc",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57cb22a8a8b14c77a280fa01e853106b",
            "value": 6
          }
        },
        "8fbefef14f994a039025154df0dcb7dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b57f9de198c42988690102e2f966db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c52bd40f5ec24419a2c4ec0914bf7d15",
              "IPY_MODEL_782d5564247c4f1f98129c542d8683f8",
              "IPY_MODEL_e4d6a1bdac2e45ef85e497074ac3f7d5"
            ],
            "layout": "IPY_MODEL_4a579c847c254c9fb9bd647ea8e46246"
          }
        },
        "c52bd40f5ec24419a2c4ec0914bf7d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b8bcb3e61b844d182f7310ded587cfc",
            "placeholder": "​",
            "style": "IPY_MODEL_fbf698b3b1284c8d9e596ea37132c6aa",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "e4d6a1bdac2e45ef85e497074ac3f7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_427784430f794a82ad4e6fbc9bb00a94",
            "placeholder": "​",
            "style": "IPY_MODEL_6539f3fea91d4c93b61a53137fd3ac85",
            "value": " 6/6 [00:46&lt;00:00,  9.38s/it]"
          }
        },
        "fbf698b3b1284c8d9e596ea37132c6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
